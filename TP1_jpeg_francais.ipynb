{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOKU5TkVc0Q391lUDuMShyB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<h1>Lab : simplified JPEG encoder/decoder</h1>"],"metadata":{"id":"4TNaSdUsPFi9"}},{"cell_type":"markdown","source":["# Noms :\n","# Groupe :\n","\n","# (Faites une copie pour enregistrer vos modifications.)"],"metadata":{"id":"KFyuux0nYdfp"}},{"cell_type":"markdown","source":["# Présentation du projet : Réalisation d’un codeur/décodeur JPEG simplifié\n","\n","JPEG est l’acronyme de Joint Photographic Experts Group. C’est une norme définissant le format d’enregistrement et l’algorithme de décodage pour une représentation numérique compressée d’une image.\n","\n","JPEG normalise uniquement l’algorithme et le format de décodage. Le processus d’encodage est quant à lui laissé libre à la compétition des industriels et des universitaires. La seule contrainte est que l’image produite doit pouvoir être décodée par un décodeur respectant le standard.\n","\n","Le format JPEG permet de compresser les données d’une image. Il existe un processus de compression sans pertes (ou réversible) qui permet de revenir exactement aux valeurs de l’image avant encodage. Son taux de compression est inférieur à celui d’une compression avec pertes (ou irréversible). Dans les cas où la taille de l’image est un critère plus important que la qualité, on privilégiera une compression avec pertes.\n","\n","\n","# I. Structure d'une image (non compressée)\n","\n","L’image de départ est un tableau de M sur N pixels. Pour une image en niveau de gris, chaque pixel est codé sur un octet (valeurs comprises entre 0 et 255).\n","\n","Pour une image couleur, chaque pixel est codé sur trois octets, qui représentent les intensités des trois composantes couleur : le rouge, le vert et le bleu.\n","\n","## Conversion en luminance/chrominance\n","\n","Une autre représentation que le RGB est souvent utilisée : le YCbCr, qui correspond à la luminance Y (intensité du pixel en niveau de gris) et deux chrominances (une rouge Cr et une bleue Cb). L’image est alors constituée de trois tableaux d’octets, associés respectivement aux trois grandeurs Y, Cr, Cb.\n","\n","Les formules permettant de passer d’une représentation à l’autre sont les suivantes :\n","\n","$$ Y = 0.299R + 0.587G + 0.114B $$\n","$$ Cb = -0.1687R - 0.3313G + 0.5B + 128 $$\n","$$ Cr = 0.5R - 0.4187G - 0.0813B + 128 $$\n","\n","$$\n","R = Y + 1.14020 \\times (Cr - 128)\n","$$\n","\n","$$\n","G = Y - 0.34414 \\times (Cb - 128) - 0.71414 \\times (Cr - 128)\n","$$\n","\n","$$\n","B = Y + 1.77200 \\times (Cb - 128)\n","$$\n","\n","**Remarque** : $R$, $G$, $B$ sont compris entre 0 et 255. Ces formules peuvent donner des valeurs YCbCr qui sortent de cet intervalle, et qui devront être saturées si nécessaire afin de les garder comprises entre 0 et 255.\n","\n","Deux formats différents sont fréquemment utilisés :\n","\n","- Dans le format le plus simple, les trois tableaux Y, Cr, Cb ont les mêmes dimensions, $M$ et $N$, égales aux dimensions de l’image originale.\n","  \n","- Un format plus efficace en termes de compression (et donc plus souvent utilisé) consiste à sous-échantillonner les deux signaux de chrominance d’un facteur 2 (ou 4). Plus précisément, avec le facteur 2, le tableau Y reste de taille $[M, N]$ mais les tableaux Cr et Cb sont de dimension $[M/2, N/2]$ (la valeur de chrominance est associée à quatre pixels voisins).\n","\n","# II. Encodage d'une data unit\n","\n","\n","Le codeur JPEG travaille sur des *data units*, qui sont des blocs de taille 8x8 pixels d’une image. Chaque composante est découpée en carrés de 8x8 pixels. Si les dimensions de la composante ne sont pas des multiples\n","de 8, l’image est complétée par duplication de la dernière ligne (ou colonne) jusqu’à obtenir le multiple de 8 immédiatement supérieur. Chaque carré 8x8 est ensuite traité indépendamment, en décrivant l’image de\n","gauche à droite et de haut en bas.\n","\n","## II.1. Centrage\n","\n"," Les échantillons des carrés 8x8 sont des nombres compris entre 0 et 255.  \n"," La première opération à réaliser est un centrage afin d’obtenir des valeurs comprises entre -128 et 127 (en retirant 128 à chaque valeur).  \n"," Les valeurs centrées seront notées f(i,j) avec i,j ∈ [0, 7].\n","\n","\n","## II.2. Transformée en cosinus discrète (DCT)\n","\n","Après avoir réalisé le centrage, il faut calculer la transformée en cosinus discrète (DCT) de chaque carré 8x8.  \n","Cette transformation donne une nouvelle matrice 8x8 de coefficients, appelée F(u,v), avec u,v ∈ [0, 7].  \n","\n","La DCT est une variante de la transformée de Fourier. Elle décompose un bloc, considéré comme une fonction numérique  \n","à deux variables, en une somme de fonctions cosinus oscillant à des fréquences différentes.  \n","Chaque bloc est ainsi décrit en une carte de fréquences et en amplitudes plutôt qu’en pixels et coefficients de couleur.  \n","Pour le décodage, on peut retrouver les $f(i,j)$ à partir de la transformée 2D inverse des $F(u,v)$.\n","\n","Équations de la DCT et de son inverse :\n","\n","\n","$$ F(u, v) = C_u C_v \\sum_{i=0}^{7} \\sum_{j=0}^{7} f(i,j) \\cos \\left( \\frac{(2i + 1) u \\pi}{16} \\right) \\cos \\left( \\frac{(2j + 1) v \\pi}{16} \\right) $$\n","\n","$$ f(i, j) = \\sum_{u=0}^{7} \\sum_{v=0}^{7} C_u C_v F(u,v) \\cos \\left( \\frac{(2i + 1) u \\pi}{16} \\right) \\cos \\left( \\frac{(2j + 1) v \\pi}{16} \\right) $$\n","\n","\n","avec  $ C_0 = \\frac{1}{\\sqrt{8}} $ et $ C_u = \\frac{1}{2}$  si $ u \\neq 0 $.\n","\n","L’application de la DCT est une opération théoriquement sans perte d’informations : les coefficients initiaux peuvent être retrouvés en appliquant la DCT inverse au résultat de la DCT.  \n","\n","Ces transformations en deux dimensions sont séparables, car elles peuvent être réalisées en appliquant des transformations en une dimension, successivement sur les lignes et les colonnes.\n","\n","## II.3. Quantification\n","\n","La quantification est l'étape qui permet de gagner le plus de place (la DCT n'effectue aucune compression).  \n","La DCT a retourné, pour chaque bloc, une matrice de 8x8 nombres.  \n","La quantification consiste à diviser point à point cette matrice par une matrice de quantification également 8x8.  \n","Soit $ Q $ la matrice de quantification.\n","\n","Le bloc 8x8 après compression sera obtenu par :\n","\n","$$\n","\\hat{F}(u, v) = \\text{round}\\left(\\frac{F(u,v)}{Q(u,v)}\\right) \\tag{3}\n","$$\n","\n","Le but est d’atténuer les hautes fréquences car l’œil humain y est très peu sensible. Ces fréquences ont des amplitudes faibles, et elles sont souvent ramenées à 0 après la quantification. Ces coefficients sont situés dans la matrice en bas à droite. Le but va être de ne garder que quelques informations essentielles (concentrées dans le coin en haut à gauche) pour représenter le bloc. Le reste de la matrice sera essentiellement composé de 0, ce qui va permettre d’utiliser un codage **RunLength** afin de gagner de la place.\n","\n","\n","Les matrices de quantification sont les éléments centraux de la compression avec pertes parce que c’est la\n","quantification qui permet de régler les pertes, et donc le taux de compression. En toute rigueur, ces matrice\n","devraient être calculées pour chaque image, en tenant compte du taux de compression désiré et des propriétés\n","de l’image et de l’oeil. En pratique, ce calcul est complexe, et l’on pourra dans ce projet utiliser les matrices\n","précalculées.\n","\n","Pour la quantification d’une composante RGB ou de la composante luminance, la matrice $Q$ est :\n","\n","| 16  | 11  | 10  | 16  | 24  | 40  | 51  | 61  |\n","|-----|-----|-----|-----|-----|-----|-----|-----|\n","| 12  | 12  | 14  | 19  | 26  | 58  | 60  | 55  |\n","| 14  | 13  | 16  | 24  | 40  | 57  | 69  | 56  |\n","| 14  | 17  | 22  | 29  | 51  | 87  | 80  | 62  |\n","| 18  | 22  | 37  | 56  | 68  | 109 | 103 | 77  |\n","| 24  | 35  | 55  | 64  | 81  | 104 | 113 | 92  |\n","| 49  | 64  | 78  | 87  | 103 | 121 | 120 | 101 |\n","| 72  | 92  | 95  | 98  | 112 | 100 | 103 | 99  |\n","\n","Pour la quantification d’une chrominance, la matrice $Q$ est :\n","\n","| 17  | 18  | 24  | 47  | 99  | 99  | 99  | 99  |\n","|-----|-----|-----|-----|-----|-----|-----|-----|\n","| 18  | 21  | 26  | 66  | 99  | 99  | 99  | 99  |\n","| 24  | 26  | 56  | 99  | 99  | 99  | 99  | 99  |\n","| 47  | 66  | 99  | 99  | 99  | 99  | 99  | 99  |\n","| 99  | 99  | 99  | 99  | 99  | 99  | 99  | 99  |\n","| 99  | 99  | 99  | 99  | 99  | 99  | 99  | 99  |\n","| 99  | 99  | 99  | 99  | 99  | 99  | 99  | 99  |\n","| 99  | 99  | 99  | 99  | 99  | 99  | 99  | 99  |\n","\n","\n","\n","**Remarque** : dans un premier temps du projet, faire la quantification en utilisant ces matrices de quantification. Ensuite, tester la compression en modifiant les matrices de quantification avec un facteur de qualité.\n","\n","Soit $f_q$ le facteur de qualité (entre 1 et 100), définir s :\n","\n","si $f_q < 50$, alors $s = \\frac{5000}{f_q}$.\n","\n","sinon, $s = 200 - 2 \\times f_q$.\n","\n","Puis calculer la nouvelle matrice de quantification $Q_2$ par la formule :\n","\n","$$\n","Q_2 = \\left\\lfloor \\frac{(s \\times Q + 50)}{100} \\right\\rfloor\n","$$\n","\n","\n","## II.4. Parcours en zigzag, Run-Length Coding (RLC) et codage de Huffman\n","\n","Comme dit dans la section précédente, après la quantification, beaucoup de coefficients de la matrice $\\hat{F}$ sont nuls et sont localisés en bas à droite de cette matrice. Le nombre de bits moyen de ces coefficients est donc très réduit.\n","\n","Afin d’exploiter cette propriété, le bloc 8x8 sera lu avec un parcours zigzag  afin de construire de longues plages de 0 (afin d’optimiser au mieux l’utilisation d’un RLC sur le symbole 0).\n","\n","\n","![](https://upload.wikimedia.org/wikipedia/commons/1/1f/JPEG_example_zigzag.png)\n","\n","Une fois le vecteur contenant les 64 valeurs du bloc 8x8 construit, il faut eﬀectuer un codage RunLength\n","pour obtenir le vecteur Vrlc : dès qu’une plage de 0 est détectée, il faut préciser la longueur de cette plage,\n","précédée du nombre 257.\n","\n","Une fois les vecteurs codant le RLC codés, il faut eﬀectuer un codage de Huﬀman pour les Vrlc.\n","\n","**Remarque**\n","\n","En pratique, dans un bloc 8x8, on distingue deux types de coeﬃcient : le coeﬃcient $\\hat{F}(0,0)$ est appelé\n","coeﬃcient **DC**, et les autres 63 coeﬃcients sont appelés coeﬃcients **AC** (qui sont très faibles ou nuls après\n","quantification). Les coeﬃcients DCs et ACs sont codés diﬀéremment.\n","\n","DC : la valeur DC d’un bloc correspond à sa valeur moyenne. Elle est la première valeur du bloc, située\n","à la position (0, 0). En faisant l’hypothèse qu’elle est généralement voisine de celles des blocs voisins (vrai\n","sauf en cas de changement brusque de couleurs ou de zones), la diﬀérence entre deux valeurs DC de blocs\n","voisins de la même composante (luminance ou chrominance) est plutôt faible. Ainsi, au lieu d’encoder les\n","valeurs DC issues de la quantification, on préfère encoder cette diﬀérence. On encode donc les DCs par le\n","codage diﬀérentiel (DPCM Diﬀerential Pulse Code Modulation) et le code de Huﬀman.\n","\n","AC : Les coeﬃcients AC sont donc les 63 valeurs restantes dans le bloc 8 x 8. L’étape de quantification et\n","le ré-ordonnancement ont eu pour but de mettre à 0 les hautes fréquences. On encode les ACs par le codage\n","RLE et le code de Huﬀman.\n","\n","\n","\n","#III.  Décodage et reconstruction\n","Le décodage d’une data unit va défaire tous les étapes précédentes les unes après les autres. La première\n","étape consistera à décoder le code de Huﬀman de la data unit afin de reconstruire le vecteur Vrlc. De là, on\n","peut reconstruire les 64 valeurs de bloc 8x8, puis inverser l’opération de quantification et de DCT.\n","\n","#IV. Implémentation\n","Les blocs nécessaires à la mise en oeuvre du codeur/décodeur simplifié détaillé précédemment sont les suivants :\n","\n","•Découpage en bloc de taille 8x8\n","\n","•Centrage, DCT et quantification de chaque bloc\n","\n","•RunLength coding\n","\n","•Codage de Huﬀman\n","\n","•Les fonctions inverses de chacun des points précédents\n","\n","Dans un premier temps, commencer par travailler avec des images en noir et blanc (encoder les DCs\n","et ACs de la même manière). Par la suite, si tous les blocs fonctionnent correctement, passer à une image\n","couleur en vérifiant d’abord avec la représentation RGB puis la représentation luminance/chrominances.\n","Ensuite, encoder les DCs et ACs en utilisant deux tableaux de codage diﬀérentes (voir le remarque).\n","\n","\n","**Conseil** : Calculer et aﬃcher le résultat de diﬀérentes étapes (les résultats du DCT et de la quantification de diﬀérents blocs).\n","\n","Calculer le taux de compression, les erreurs, le PSNR.\n"],"metadata":{"id":"OLRXldRSF-t6"}},{"cell_type":"markdown","source":["# VERY IMPORTANT: Take time to read the guidance before coding.\n","\n","**Functions to be implemented:**\n","  - rlencode (in Section 1), (but you dont need them immediately, you can code them later)\n","  - count_symbols (in Section 1), (but you dont need them immediately, you can code them later)\n","  - and also the 'main' functions (in Section 3)\n","\n","**Some given functions:** (in Section 2)\n","  - zigzag\n","  - functions related to Huffman coding, such as ``construct_huffman_table, encode_huffman, decode_huffman``\n","\n","**Some useful functions:**\n","  - imshow()\n","  - img = cv2.cvtColor(imgOriginal, cv2.COLOR_BGR2GRAY)\n","  - cv2.dct\n","\n","# **You can directly go to Section 3 and code there**"],"metadata":{"id":"ALTlzTtw_Yop"}},{"cell_type":"markdown","source":["**Import the libs**"],"metadata":{"id":"mfLPXd_-_gSE"}},{"cell_type":"code","source":["import numpy as np\n","import requests\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from typing import List, Tuple, Any, Dict, Optional\n","\n","import cv2\n","\n","def show(img:np.ndarray):\n","    im = Image.fromarray(img)\n","    print(im.size, im.mode, im.format, img.min(),  img.max())\n","    display(im)\n","\n","def load_from_url(url: str) -> np.ndarray:\n","    return np.asarray(Image.open(requests.get(url, stream=True).raw))\n","\n","def debug_ndarray(arr:np.ndarray, name:str='') -> None:\n","    print(name, arr.shape, arr.dtype, arr.min(), arr.max())\n","\n","def imshow(img):\n","    import cv2\n","    import IPython\n","    _,ret = cv2.imencode('.jpg', img)\n","    i = IPython.display.Image(data=ret)\n","    IPython.display.display(i)"],"metadata":{"id":"YVoNmxrfHQqe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Functions to be implemented\n","\n","*   rlencode: Run length coding\n","*   count_symbols: this will be used for Huffman coding\n","*   zigzag: Implementing this function is optional, as there is a relatively simple 'manual' method available for accomplishing the task (see the begining of Section 3)\n","# *   **Note: however, you dont need to implement these functions immediately. You can go to Section 3 to implement different first steps of JPEG: block devivision, centering, DCT, quantification.**\n","\n","\n","\n"],"metadata":{"id":"ZomdSCGdjJuH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZeU-n-zeGUzU","executionInfo":{"status":"ok","timestamp":1679056703322,"user_tz":-60,"elapsed":9,"user":{"displayName":"Ngoc Son VU","userId":"09950164676861804363"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2358f94b-b7ba-497b-a172-22fc0fabb6c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 4, 1: 3, 2: 2, 3: 1}\n"]}],"source":["def zigzag(matrix: np.ndarray) -> np.ndarray:\n","    \"\"\"\n","    computes the zigzag of a quantized block\n","    :param numpy.ndarray matrix: quantized matrix\n","    :returns: zigzag vectors in an array\n","    \"\"\"\n","    # initializing the variables\n","    h = 0\n","    v = 0\n","    v_min = 0\n","    h_min = 0\n","    v_max = matrix.shape[0]\n","    h_max = matrix.shape[1]\n","    i = 0\n","    output = np.zeros((v_max * h_max))\n","\n","    while (v < v_max) and (h < h_max):\n","        if ((h + v) % 2) == 0:  # going up\n","            if v == v_min:\n","                output[i] = matrix[v, h]  # first line\n","                if h == h_max:\n","                    v = v + 1\n","                else:\n","                    h = h + 1\n","                i = i + 1\n","            elif (h == h_max - 1) and (v < v_max):  # last column\n","                output[i] = matrix[v, h]\n","                v = v + 1\n","                i = i + 1\n","            elif (v > v_min) and (h < h_max - 1):  # all other cases\n","                output[i] = matrix[v, h]\n","                v = v - 1\n","                h = h + 1\n","                i = i + 1\n","        else:  # going down\n","            if (v == v_max - 1) and (h <= h_max - 1):  # last line\n","                output[i] = matrix[v, h]\n","                h = h + 1\n","                i = i + 1\n","            elif h == h_min:  # first column\n","                output[i] = matrix[v, h]\n","                if v == v_max - 1:\n","                    h = h + 1\n","                else:\n","                    v = v + 1\n","                i = i + 1\n","            elif (v < v_max - 1) and (h > h_min):  # all other cases\n","                output[i] = matrix[v, h]\n","                v = v + 1\n","                h = h - 1\n","                i = i + 1\n","        if (v == v_max - 1) and (h == h_max - 1):  # bottom right element\n","            output[i] = matrix[v, h]\n","            break\n","    return output\n","\n","\n","def rlencode(data:list, symbol:int=0, escape=257) -> np.ndarray:\n","    '''\n","    Encode a list of values using run length encoding\n","    when `symbol` is encountered,\n","    the next value is `escape` followed by the number of `symbol`.\n","    '''\n","    out = []\n","\n","\n","    ##############################\n","\n","\n","\n","    #TODO\n","\n","\n","\n","    ##############################\n","\n","\n","\n","    return np.array(out)\n","\n","def count_symbols(data:list) -> Dict[Any, int]:\n","    '''\n","    Compute the frequency of each value in the list\n","    '''\n","    freq = {}\n","\n","    ##############################\n","\n","    #TODO\n","\n","\n","    ##############################\n","    return freq\n","\n","\n","#testing\n","freq = count_symbols([0, 0, 0, 0, 1, 1, 1, 2, 2, 3])\n","print(freq)\n","#'output: {0: 4, 1: 3, 2: 2, 3: 1}'\n"]},{"cell_type":"markdown","source":["#2. Given functions"],"metadata":{"id":"le6YotStjsQI"}},{"cell_type":"markdown","source":["**Huffman tree**\n","\n","To obtain the Huffman code, it is necessary to construct a (binary) Huffman tree.\n","This tree is constructed from a list of leaves (symbols) and internal nodes (sum of the weights of the children).\n","Each node is associated with a value which is the sum of the values of its children.\n","The leaves correspond to symbols and are associated with their number of occurrences in the vector.\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Huffman_tree_2.svg/1200px-Huffman_tree_2.svg.png\" width=500>\n","\n","Huffman encoding involves counting the number of occurrences of each character in a sentence and representing each character as a leaf node on a tree with a weight equal to its occurrence count. The tree is constructed by combining the two nodes with the lowest weights at each step until only one node, the root of the tree, remains."],"metadata":{"id":"1LSz2RabIc-y"}},{"cell_type":"code","source":["def compute_huffman_tree(data:list, freq:Optional[dict]=None) -> Tuple[int, Any, Any]:\n","    '''\n","    Compute a huffman tree from a frequency table of values\n","    Return the root node of the tree\n","    '''\n","    if freq is None:\n","        freq: Dict[Any, int] = count_symbols(data)\n","\n","    # create a list of nodes\n","    nodes = []\n","    for symbol, freq in freq.items():\n","        nodes.append((freq, symbol))\n","\n","    # sort the list of nodes by count\n","    nodes.sort(key=lambda x: x[0])\n","\n","    # create a tree\n","    while len(nodes) > 1:\n","        # get the two lowest frequency nodes\n","        left, right = nodes[:2]\n","\n","        # create a new node with the sum of the frequencies\n","        new_node_count = left[0] + right[0]\n","        new_node = (new_node_count, left, right)\n","        # remove the two lowest frequency nodes\n","        nodes = nodes[2:]\n","        # insert the new node\n","        nodes.append(new_node)\n","        # sort the nodes by frequency\n","        nodes.sort(key=lambda x: x[0])\n","\n","    # return the root node\n","    return nodes[0]\n","\n","sentence = \"this is an example of a huffman tree\"\n","#convert sentence to list of characters\n","data = list(sentence)\n","\n","from pprint import pprint\n","\n","data_tree = compute_huffman_tree(data)\n","pprint(data_tree)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YQzzUWkdCgYn","executionInfo":{"status":"ok","timestamp":1679056703323,"user_tz":-60,"elapsed":8,"user":{"displayName":"Ngoc Son VU","userId":"09950164676861804363"}},"outputId":"ea3de6f7-ad1b-499a-f095-47d954696bc4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(36,\n"," (16,\n","  (8, (4, 'a'), (4, 'e')),\n","  (8, (4, (2, 't'), (2, 'h')), (4, (2, 'i'), (2, 's')))),\n"," (20,\n","  (8,\n","   (4, (2, 'n'), (2, 'm')),\n","   (4, (2, (1, 'x'), (1, 'p')), (2, (1, 'l'), (1, 'o')))),\n","  (12, (5, (2, (1, 'u'), (1, 'r')), (3, 'f')), (7, ' '))))\n"]}]},{"cell_type":"markdown","source":["**Huffman coding table**\n","\n","Read and test the following functions"],"metadata":{"id":"aVF8AjN2JaRY"}},{"cell_type":"code","source":["def display_table(lines, code:dict, sep='\\t'):\n","    '''\n","    Display a table of data with columns aligned\n","    '''\n","    cols_width = [max(len(str(x)) for x in col) for col in zip(*lines)]\n","    for line in lines:\n","        # adjust each column to its max width\n","        print(*[x.rjust(w) for x, w in zip(line, cols_width)], sep=sep)\n","\n","def display_huffman_table(data, code:dict, sep='\\t'):\n","    counts: dict = count_symbols(data)\n","    total = sum(counts.values())\n","    lines = [('Symbol', 'Code', 'Count', 'Frequency')]\n","    tmp = sorted(list(counts.keys()), key=lambda x: counts[x], reverse=True)\n","    for k in tmp:\n","        symbol = f\"`{k}`\"\n","        symbol_code = str(counts[k])\n","        count = str(code[k])\n","        freq = str(round(100 * counts[k] / total, 2))+'%'\n","        lines.append((symbol, symbol_code, count, freq))\n","    display_table(lines, code, sep=sep)\n","\n","def bintree_to_table(node, path=None, left='0', right='1') -> Dict[str, str]:\n","    '''\n","    Build a huffman table from a huffman tree\n","    Return a dictionary of symbol:code\n","    '''\n","    if path is None:\n","        path = ''\n","    table = {}\n","    if len(node) == 2: # leaf node\n","        count, symbol = node\n","        table[symbol] = path\n","    else: # internal node\n","        node_left, node_right = node[1], node[2]\n","        left_path = bintree_to_table(node_left, path + left, left=left, right=right)\n","        right_path = bintree_to_table(node_right, path + right, left=left, right=right)\n","        table.update(left_path)\n","        table.update(right_path)\n","\n","    return table\n","\n","sentence = \"this is an example of a huffman tree\"\n","#convert sentence to list of characters\n","data = list(sentence)\n","data_tree = compute_huffman_tree(data)\n","data_table = bintree_to_table(data_tree)\n","\n","# display the huffman table\n","display_huffman_table(data, data_table)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htmZMdetC1Oh","executionInfo":{"status":"ok","timestamp":1679056704463,"user_tz":-60,"elapsed":17,"user":{"displayName":"Ngoc Son VU","userId":"09950164676861804363"}},"outputId":"f3ac0c87-df35-4b26-b42e-867bd85e34f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Symbol\tCode\tCount\tFrequency\n","   ` `\t   7\t  111\t   19.44%\n","   `a`\t   4\t  000\t   11.11%\n","   `e`\t   4\t  001\t   11.11%\n","   `f`\t   3\t 1101\t    8.33%\n","   `t`\t   2\t 0100\t    5.56%\n","   `h`\t   2\t 0101\t    5.56%\n","   `i`\t   2\t 0110\t    5.56%\n","   `s`\t   2\t 0111\t    5.56%\n","   `n`\t   2\t 1000\t    5.56%\n","   `m`\t   2\t 1001\t    5.56%\n","   `x`\t   1\t10100\t    2.78%\n","   `p`\t   1\t10101\t    2.78%\n","   `l`\t   1\t10110\t    2.78%\n","   `o`\t   1\t10111\t    2.78%\n","   `u`\t   1\t11000\t    2.78%\n","   `r`\t   1\t11001\t    2.78%\n"]}]},{"cell_type":"markdown","source":["***Take time to test the three following functions, you will use them for Huffman codage/decodage***"],"metadata":{"id":"Qgc-4Sh1Mw-n"}},{"cell_type":"code","source":["def construct_huffman_table(data:list) -> dict:\n","    '''\n","    Encode a list of values using huffman encoding and return the huffman table\n","    '''\n","    counts = count_symbols(data)\n","    tree = compute_huffman_tree(counts)\n","    table = bintree_to_table(tree)\n","    return table\n","\n","def encode_huffman(data: list, table: dict) -> str:\n","    '''\n","    Encode a list of values using the huffman table dictionary\n","    Return the encoded string\n","    '''\n","    out = []\n","    for i in data:\n","        out.extend(table[i])\n","    out = ''.join(out) # list to string\n","    return out\n","\n","def decode_huffman(encoded:str, table: dict) -> np.ndarray:\n","    '''\n","    Decode a list of values using huffman code dictionary\n","    '''\n","    data = []\n","    i = 0\n","    while i < len(encoded):\n","        for k, v in table.items():\n","            if encoded[i:].startswith(v): # prefix match\n","                data.append(k)\n","                i += len(v)\n","                break\n","    return np.array(data)\n","\n","# testing\n","sentence = \"this is an example of a huffman tree\"\n","#convert sentence to list of characters\n","data = list(sentence)\n","table = construct_huffman_table(data)\n","print(\"Test 1\")\n","print(table)\n","\n","# Testing\n","print(\"Test 2\")\n","data = [0, 1, 0, 0, 0, 0, 0, 2, 0, 4, 4, 2, 3]\n","data_table = construct_huffman_table(data)\n","print('Original :', data)\n","\n","encoded = encode_huffman(data, data_table)\n","print('Encoded  :', encoded)\n","\n","decoded = decode_huffman(encoded, data_table)\n","print('Decoded  :', decoded)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7HyHuEeuC_fv","executionInfo":{"status":"ok","timestamp":1679056704464,"user_tz":-60,"elapsed":14,"user":{"displayName":"Ngoc Son VU","userId":"09950164676861804363"}},"outputId":"63912db2-5b5b-4cb3-be3a-eb32658b007a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test 1\n","{'t': '0000', 'h': '0001', 'i': '0010', 's': '0011', ' ': '0100', 'a': '0101', 'n': '0110', 'e': '0111', 'x': '1000', 'm': '1001', 'p': '1010', 'l': '1011', 'o': '1100', 'f': '1101', 'u': '1110', 'r': '1111'}\n","Test 2\n","Original : [0, 1, 0, 0, 0, 0, 0, 2, 0, 4, 4, 2, 3]\n","Encoded  : 1101111101101101101100011001010010\n","Decoded  : [0 1 0 0 0 0 0 2 0 4 4 2 3]\n"]}]},{"cell_type":"markdown","source":["#3. TODO: Codage/Decodage"],"metadata":{"id":"CA6LGOo8j01k"}},{"cell_type":"markdown","source":["# The following code demonstrates how to manually implement zig-zag, which is an important step in JPEG. You will need it later."],"metadata":{"id":"nVqO0ngWOnYg"}},{"cell_type":"code","source":["# ZigZag example\n","\n","# This will be used for of ZigZag...\n","col = np.array([1, 2, 1, 1, 2, 3, 4, 3, 2, 1, 1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 1, 1, 2, 3, 4, 5,\n","                6, 7, 8, 7, 6, 5, 4, 3, 2, 1, 2, 3, 4, 5, 6, 7, 8, 8, 7, 6, 5, 4, 3, 4, 5, 6, 7, 8, 8, 7, 6, 5, 6, 7, 8, 8, 7, 8])\n","\n","lig = np.array([1, 1, 2, 3, 2, 1, 1, 2, 3, 4, 5, 4, 3, 2, 1, 1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2, 1, 1, 2,\n","                3, 4, 5, 6, 7, 8, 8, 7, 6, 5, 4, 3, 2, 3, 4, 5, 6, 7, 8, 8, 7, 6, 5, 4, 5, 6, 7, 8, 8, 7, 6, 7, 8, 8])\n","\n","rdMatrix = np.round(np.random.rand(8,8)*10)\n","\n","out = np.zeros(64)\n","for k in range(64):\n","    out[k] = rdMatrix[lig[k]-1,col[k]-1] # -1 since indexes start from 0 in Python...\n","\n","print(rdMatrix)\n","print(out)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ic0nKKMFDs2u","executionInfo":{"status":"ok","timestamp":1679299944612,"user_tz":-60,"elapsed":205,"user":{"displayName":"Ngoc Son VU","userId":"09950164676861804363"}},"outputId":"251fafc3-28fd-49d9-a745-a3dd766508b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 7.  6.  1.  6. 10.  4.  8.  5.]\n"," [ 1.  4.  9.  8.  8.  6.  1.  9.]\n"," [ 7.  9.  2.  7.  8.  1.  8.  3.]\n"," [ 1.  4.  4.  9.  5.  9.  8.  2.]\n"," [ 4.  1.  1.  8.  6. 10.  4.  5.]\n"," [ 0.  1.  1.  5.  2.  7.  3.  1.]\n"," [ 4.  5.  6.  5.  9.  9. 10.  7.]\n"," [ 8.  7.  7.  9.  0.  4.  6.  8.]]\n","[ 7.  6.  1.  7.  4.  1.  6.  9.  9.  1.  4.  4.  2.  8. 10.  4.  8.  7.\n","  4.  1.  0.  4.  1.  1.  9.  8.  6.  8.  5.  1.  1.  5.  8.  1.  5.  8.\n","  7.  6.  5.  6.  9.  8.  9.  3.  8. 10.  2.  5.  7.  9.  9.  7.  4.  2.\n","  5.  3.  9.  0.  4. 10.  1.  7.  6.  8.]\n"]}]},{"cell_type":"markdown","source":["# Now, you can code."],"metadata":{"id":"IzuZAdWxOycb"}},{"cell_type":"code","source":["# define quantization tables\n","qY = np.array([[16, 11, 10, 16, 24, 40, 51, 61],  # luminance quantization table\n","                [12, 12, 14, 19, 26, 48, 60, 55],\n","                [14, 13, 16, 24, 40, 57, 69, 56],\n","                [14, 17, 22, 29, 51, 87, 80, 62],\n","                [18, 22, 37, 56, 68, 109, 103, 77],\n","                [24, 35, 55, 64, 81, 104, 113, 92],\n","                [49, 64, 78, 87, 103, 121, 120, 101],\n","                [72, 92, 95, 98, 112, 100, 103, 99]])\n","\n","qC = np.array([[17, 18, 24, 47, 99, 99, 99, 99],  # chrominance quantization table\n","                [18, 21, 26, 66, 99, 99, 99, 99],\n","                [24, 26, 56, 99, 99, 99, 99, 99],\n","                [47, 66, 99, 99, 99, 99, 99, 99],\n","                [99, 99, 99, 99, 99, 99, 99, 99],\n","                [99, 99, 99, 99, 99, 99, 99, 99],\n","                [99, 99, 99, 99, 99, 99, 99, 99],\n","                [99, 99, 99, 99, 99, 99, 99, 99]])\n","\n","# read an image and show it\n","url = \"http://www.lenna.org/len_std.jpg\"\n","\n","# url = \"https://www.hlevkin.com/hlevkin/TestImages/baboon.bmp\"\n","imgOriginal= load_from_url(url)\n","show(imgOriginal)\n","\n","#TODO: show different channels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"4VTZaPReQkoG","executionInfo":{"status":"error","timestamp":1741869463367,"user_tz":-60,"elapsed":261,"user":{"displayName":"Ngoc Son VU","userId":"09950164676861804363"}},"outputId":"de0bf4bf-0137-4896-fb4a-b40f41f2e6ec"},"execution_count":null,"outputs":[{"output_type":"error","ename":"UnidentifiedImageError","evalue":"cannot identify image file <_io.BytesIO object at 0x79c5d411bec0>","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-6b6be92a0189>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.hlevkin.com/hlevkin/TestImages/baboon.bmp\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mimgOriginal\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mload_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgOriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-115980a0e1c1>\u001b[0m in \u001b[0;36mload_from_url\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdebug_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3530\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3531\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3532\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mUnidentifiedImageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x79c5d411bec0>"]}]},{"cell_type":"code","source":["# For students\n","# TODO: Write your 'main' code\n","# convert color image into gray image (or image in YCrCb space)\n","\n","# This is just an example of coding, you can make your code differently\n","\n","# ADVICE: create an other 'Code cell' and write/test your code gradually there\n","# since the code given here is not exectable yet\n","\n","img = cv2.cvtColor(...)\n","# color\n","# First, you can work with only gray images for simplicity\n","\n","\n","width = len(img[0])\n","height = len(img)\n","\n","#\n","img_gray = np.zeros((height, width), np.float32) + img[:, :, 0]\n","#\n","\n","#show img_gray\n","\n","# define block size\n","\n","# compute number of blocks\n","\n","# padding\n","\n","# luminance channels\n","\n","# for color images -----\n","# chrominance channels should be sub-sampled with different sub-sampling factors\n","# A very simple way: using a 2x2 averaging filter # another type of filter can be used\n","# then we can work with the sub-sampled version...\n","#--------------------\n","\n","# define empty matrices to store Dct\n","# imgDct\n","\n","# define empty matrices to store the quantized values\n","# imgQ\n","\n","\n","# This will be used for of ZigZag...\n","col = np.array([1, 2, 1, 1, 2, 3, 4, 3, 2, 1, 1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 1, 1, 2, 3, 4, 5,\n","                6, 7, 8, 7, 6, 5, 4, 3, 2, 1, 2, 3, 4, 5, 6, 7, 8, 8, 7, 6, 5, 4, 3, 4, 5, 6, 7, 8, 8, 7, 6, 5, 6, 7, 8, 8, 7, 8])\n","\n","lig = np.array([1, 1, 2, 3, 2, 1, 1, 2, 3, 4, 5, 4, 3, 2, 1, 1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2, 1, 1, 2,\n","                3, 4, 5, 6, 7, 8, 8, 7, 6, 5, 4, 3, 2, 3, 4, 5, 6, 7, 8, 8, 7, 6, 5, 4, 5, 6, 7, 8, 8, 7, 6, 7, 8, 8])\n","\n","\n","ZZ_Blk = np.zeros(blockSize * blockSize) #1D\n","\n","vRLC = []\n","\n","size_vRLC = 0\n","\n","#pseudo-code\n","for i in range('number of block'): #of course, this needs to be computed\n","    for j in range('number of block'):\n","        block = y[ ....]). # extract the block\n","\n","        # dct\n","        # you can use something like imgDct['index'] = ...\n","\n","        # quantification\n","        # you can use something like imgQ['index'] = ...\n","\n","        # easy ZigZag Version 2:\n","        ZZ_Blk = ...#\n","        # zigzag (1D)\n","\n","        # run length coding (1D)\n","        # can use `extend` function of numpy vRLC.extend()\n","\n","#end for\n","\n","\n","# Huffman\n","mat_table: dict = construct_huffman_table...\n","mat_encoded: str = encode_huffman..."],"metadata":{"id":"KByoWLLM8ZVd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# For testing a block, all steps (notably zigzag, rlc) are OK\n"],"metadata":{"id":"LwHA-Go0Z09u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Compute compression rates at different stages**"],"metadata":{"id":"VhjEJ_I5kPiW"}},{"cell_type":"code","source":["# number of bits in original image\n","H, W, C = img.shape\n","\n","\n","print(size_yRLC)"],"metadata":{"id":"85TaO4a3GdFS","executionInfo":{"status":"ok","timestamp":1679056704867,"user_tz":-60,"elapsed":15,"user":{"displayName":"Ngoc Son VU","userId":"09950164676861804363"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5f191bb4-5fd5-4786-848b-99131230ad9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of bits (original) : 524288\n","Number of elelemnts (yRLC)  : 15256\n","Number of bits (encoded)  : 106577\n","Compression ratio: 4.92\n","256 256 3\n","15256\n"]}]},{"cell_type":"markdown","source":["**Decodage**"],"metadata":{"id":"DhFM3uMBkYt6"}},{"cell_type":"code","source":["# Huffman decoding\n","decoded = decode_huffman...\n","print(len(decoded))"],"metadata":{"id":"ZWETZPpALruV","executionInfo":{"status":"ok","timestamp":1679056795925,"user_tz":-60,"elapsed":1358,"user":{"displayName":"Ngoc Son VU","userId":"09950164676861804363"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5e49d473-a5d5-41a2-fa01-783571c2ee3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["15256\n"]}]},{"cell_type":"code","source":["print(decoded)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0PlfTBSFlHYe","executionInfo":{"status":"ok","timestamp":1679056800730,"user_tz":-60,"elapsed":255,"user":{"displayName":"Ngoc Son VU","userId":"09950164676861804363"}},"outputId":"8a2881dc-4191-4e63-fd7a-030ab4497c65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[  5.   1.   2. ...   1. 257.  46.]\n"]}]},{"cell_type":"code","source":["decoded - yRLC"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"biKCa-Uwlbaw","executionInfo":{"status":"ok","timestamp":1679056832499,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ngoc Son VU","userId":"09950164676861804363"}},"outputId":"e6b18edb-8983-47b8-b8ca-cf6ab10146a8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., ..., 0., 0., 0.])"]},"metadata":{},"execution_count":322}]}]}